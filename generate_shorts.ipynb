{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApcDULBzoa6r",
        "outputId": "443854ca-04b1-4652-d0cb-8e23b53222de"
      },
      "outputs": [],
      "source": [
        "!pip install yt_dlp TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qx-6X6wrGhT",
        "outputId": "90a69f7f-10b9-402a-a8c3-36453aee4a3f"
      },
      "outputs": [],
      "source": [
        "!pip3 install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJk4JxkhyZmC",
        "outputId": "9eefc26a-ea01-4281-8f70-9d09bc8a4a35"
      },
      "outputs": [],
      "source": [
        "!pip install openai==0.28.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP9iTRmbHnEw",
        "outputId": "6e6f5466-a5ae-42e3-ed0e-e60200d2e05b"
      },
      "outputs": [],
      "source": [
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXhc1lVwHx40"
      },
      "source": [
        "## ì˜ìƒ, ìŒì„± ë‹¤ìš´ë¡œë“œ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y72co9QppOyv"
      },
      "outputs": [],
      "source": [
        "import yt_dlp\n",
        "\n",
        "def url_to_mp3(url, output_path):\n",
        "    # ë‹¤ìš´ë¡œë“œ ì˜µì…˜ ì„¤ì •\n",
        "    ydl_opts = {\n",
        "        \"format\": \"bestaudio/best\",  # ìµœì ì˜ ì˜¤ë””ì˜¤ í’ˆì§ˆë¡œ ë‹¤ìš´ë¡œë“œ\n",
        "        \"outtmpl\": output_path,  # ì¶œë ¥ ê²½ë¡œ ë° íŒŒì¼ëª… ì„¤ì •\n",
        "        \"postprocessors\": [{  # í›„ì²˜ë¦¬ ì˜µì…˜ ì„¤ì • (ì˜¤ë””ì˜¤ í¬ë§· ë³€ê²½)\n",
        "            \"key\": \"FFmpegExtractAudio\",  # ì˜¤ë””ì˜¤ ì¶”ì¶œì„ ìœ„í•œ í›„ì²˜ë¦¬\n",
        "            \"preferredcodec\": \"mp3\",  # MP3 í¬ë§·ìœ¼ë¡œ ë³€í™˜\n",
        "            \"preferredquality\": \"192\"  # MP3 í’ˆì§ˆ 192kbpsë¡œ ì„¤ì •\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    # yt-dlpë¡œ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "\n",
        "def url_to_mp4(url, output_path):\n",
        "    \"\"\"ë¹„ë””ì˜¤+ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ (MP4 í¬ë§·)\"\"\"\n",
        "    ydl_opts = {\n",
        "        'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best',\n",
        "        'outtmpl': output_path,\n",
        "        'merge_output_format': 'mp4'  # âœ… í¬ë§· ê°•ì œ ì§€ì •\n",
        "    }\n",
        "\n",
        "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "        ydl.download([url])\n",
        "    print(f\"ğŸ¥ ë¹„ë””ì˜¤ ì €ì¥ ì™„ë£Œ: {output_path.replace('%(ext)s', 'mp4')}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxocZWXiIIU5"
      },
      "source": [
        "## ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜\n",
        "\n",
        "\n",
        "#### ì¶œë ¥ íŒŒì¼ ìƒì„±\n",
        "- whisper_response.json: ì›ë³¸ API ì‘ë‹µ ë°ì´í„° (ëª¨ë“  ë©”íƒ€ë°ì´í„° í¬í•¨)\n",
        "\n",
        "- full_transcription.txt: ì „ì²´ ë³€í™˜ í…ìŠ¤íŠ¸ (ì—°ì†ëœ ë¬¸ìì—´)\n",
        "\n",
        "- segments_timestamps.txt: ë¬¸ì¥ë³„ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ ê¸°ë¡"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xBE4fa-pjlG"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import json\n",
        "\n",
        "def mp3_to_text(file_path, api_key):\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    with open(file_path, \"rb\") as audio_file:\n",
        "        response = openai.Audio.transcribe(\n",
        "            file=audio_file,\n",
        "            model=\"whisper-1\",\n",
        "            language=\"ko\",  # í•œêµ­ì–´ ìŒì„± ì²˜ë¦¬\n",
        "            response_format=\"verbose_json\",\n",
        "            timestamp_granularities=[\"segment\"]\n",
        "        )\n",
        "\n",
        "    # JSON ì‘ë‹µ ì €ì¥\n",
        "    with open(\"whisper_response.json\", \"w\", encoding=\"UTF-8\") as file:\n",
        "        json.dump(response, file, ensure_ascii=False, indent=2)\n",
        "\n",
        "    # ì „ì²´ í…ìŠ¤íŠ¸ ì €ì¥\n",
        "    with open(\"full_transcription.txt\", \"w\", encoding=\"UTF-8\") as file:\n",
        "        file.write(response['text'])\n",
        "\n",
        "    # ì„¸ê·¸ë¨¼íŠ¸ ë° íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥\n",
        "    with open(\"segments_timestamps.txt\", \"w\", encoding=\"UTF-8\") as file:\n",
        "        for segment in response['segments']:\n",
        "            line = f\"{segment['text']} - ì‹œì‘: {segment['start']:.2f}, ì¢…ë£Œ: {segment['end']:.2f}\\n\"\n",
        "            file.write(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_eO1kXiIfST"
      },
      "source": [
        "##  ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‡¼ì¸  í¬ì¸íŠ¸ë¥¼ ì°¾ì•„ ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9-IYAd1IhbS"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "api_key=os.getenv(\"OPEN_AI_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMJqs66rrnHz"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "\n",
        "def text_to_shorts_points(full_text_path, api_key):\n",
        "    openai.api_key = api_key  # <- ìµœì‹  SDKì—ì„œëŠ” ì´ë ‡ê²Œ ì„¤ì •\n",
        "\n",
        "    # âœ… í…ìŠ¤íŠ¸ íŒŒì¼ ì—´ì–´ì„œ ë‚´ìš© ì½ê¸°\n",
        "    with open(full_text_path, \"r\", encoding=\"UTF-8\") as file:\n",
        "        full_text = file.read()\n",
        "\n",
        "    # 2. í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ChatGPTì—ê²Œ ì‡¼ì¸  í¬ì¸íŠ¸ ìš”ì²­\n",
        "    chat_response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ìµœê³ ì˜ ìœ íŠœë¸Œ í¸ì§‘ìì´ì êµìœ¡ ì „ë¬¸ê°€ì•¼.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"\"\"\n",
        "            [ê·œì¹™]\n",
        "            - ì£¼ì–´ì§€ëŠ” ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ê³µë¶€ ì¤‘ ê¼­ ì•Œì•„ì•¼ í•  í•µì‹¬ ê°œë…, ì„¤ëª…, ì˜ˆì‹œ, ê¿€íŒ ë“±ì„ í¬í•¨í•œ\n",
        "              'ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ë‹¨ ë˜ëŠ” ì—°ì†ëœ ë¬¸ì¥ ë©ì–´ë¦¬' ë‹¨ìœ„ë¡œ ë¬¶ì–´ì„œ ì‡¼ì¸ í™”ì— ì í•©í•œ í¬ì¸íŠ¸ë¥¼ ì„ ë³„í•´ì¤˜.\n",
        "            - í•™ìŠµì— ë„ì›€ì´ ë˜ê²Œ 10ë¬¸ì¥ ì´ìƒì˜ ì—°ì†ëœ ë¬¸ì¥ë“¤ë¡œ êµ¬ì„±ëœ ìì—°ìŠ¤ëŸ¬ìš´ ë©ì–´ë¦¬ì—¬ì•¼ í•´.\n",
        "            - ê° ì‡¼ì¸  í¬ì¸íŠ¸ëŠ” í•´ë‹¹ ë¶€ë¶„ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•´ì„œ ì¶œë ¥í•´ì¤˜.\n",
        "            - ë¬¸ì¥ ìˆœì„œë‚˜ ë‚´ìš©ì„ ë°”ê¾¸ì§€ ë§ê³ , ë°˜ë“œì‹œ ì›ë³¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ 'ì—°ì†ëœ ë¶€ë¶„'ë§Œ ì¶”ì¶œí•´ì¤˜.\n",
        "            - ê° ì‡¼ì¸  í¬ì¸íŠ¸ ì˜†ì—ëŠ” 'ì´ ë¶€ë¶„ì„ ì‡¼ì¸ í™” í¬ì¸íŠ¸ë¡œ ì„ íƒí•œ ì´ìœ 'ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜.\n",
        "\n",
        "            [ì¶œë ¥ í˜•ì‹]\n",
        "            1. [ì‡¼ì¸  í¬ì¸íŠ¸(ì—¬ëŸ¬ ë¬¸ì¥)] - [ì„ íƒ ì´ìœ ]\n",
        "            2. [ì‡¼ì¸  í¬ì¸íŠ¸(ì—¬ëŸ¬ ë¬¸ì¥)] - [ì„ íƒ ì´ìœ ]\n",
        "\n",
        "            [ìŠ¤í¬ë¦½íŠ¸]\n",
        "            {full_text}\n",
        "            \"\"\"}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    # 3. ê²°ê³¼ ì €ì¥\n",
        "    shorts_points = chat_response[\"choices\"][0][\"message\"][\"content\"]\n",
        "\n",
        "    with open(\"shorts_points.txt\", \"w\", encoding=\"UTF-8\") as file:\n",
        "        file.write(shorts_points)\n",
        "\n",
        "    print(\"âœ… ì‡¼ì¸  í¬ì¸íŠ¸ ì¶”ì¶œ ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSKll5p2IzkQ"
      },
      "source": [
        "## 1. ì„¸ê·¸ë¨¼íŠ¸ ì½ê¸° â†’ 2. ì‡¼ì¸  í¬ì¸íŠ¸ ì½ê¸° â†’ 3. ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ â†’ 4. ê²°ê³¼ ì €ì¥"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q63zNaeaUVCl"
      },
      "outputs": [],
      "source": [
        "from difflib import SequenceMatcher\n",
        "\n",
        "# --- 1. Whisper ì„¸ê·¸ë¨¼íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
        "def read_segments(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        return json.load(file)[\"segments\"]\n",
        "\n",
        "# --- 2. ì‡¼ì¸  í¬ì¸íŠ¸ íŒŒì‹± (ì—¬ëŸ¬ ì¤„, ë²ˆí˜¸, ì„ íƒ ì´ìœ  ë“± ì²˜ë¦¬) ---\n",
        "def read_shorts_points(file_path):\n",
        "    shorts_list = []\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        current_point = []\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if re.match(r'^\\d+\\.', line):  # \"1.\", \"2.\" ë“±ìœ¼ë¡œ ì‹œì‘\n",
        "                if current_point:\n",
        "                    full_text = ' '.join(current_point).split(' - ')[0].strip()\n",
        "                    shorts_list.append(full_text)\n",
        "                current_point = [re.sub(r'^\\d+\\.\\s*', '', line)]\n",
        "            elif line.startswith('- ì´ ë¶€ë¶„ì„'):  # ì„ íƒ ì´ìœ  ë¼ì¸ ë¬´ì‹œ\n",
        "                continue\n",
        "            elif line:\n",
        "                current_point.append(line)\n",
        "        if current_point:\n",
        "            full_text = ' '.join(current_point).split(' - ')[0].strip()\n",
        "            shorts_list.append(full_text)\n",
        "    return shorts_list\n",
        "\n",
        "# --- 3. ì„¸ê·¸ë¨¼íŠ¸ ìœˆë„ìš° ìƒì„± (ì—°ì† nê°œ ë¬¶ìŒ) ---\n",
        "def build_windows(segments, window_size=5):\n",
        "    windows = []\n",
        "    for i in range(len(segments) - window_size + 1):\n",
        "        chunk = segments[i:i + window_size]\n",
        "        text = ' '.join(seg[\"text\"] for seg in chunk)\n",
        "        windows.append({\n",
        "            \"text\": text,\n",
        "            \"start\": chunk[0][\"start\"],\n",
        "            \"end\": chunk[-1][\"end\"]\n",
        "        })\n",
        "    return windows\n",
        "\n",
        "# --- 4. ìœ ì‚¬ë„ ê³„ì‚° ---\n",
        "def similarity(a, b):\n",
        "    a = re.sub(r'\\s+', '', a)\n",
        "    b = re.sub(r'\\s+', '', b)\n",
        "    return SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "# --- 5. ì‡¼ì¸  í¬ì¸íŠ¸ì™€ ì„¸ê·¸ë¨¼íŠ¸ ìœˆë„ìš° ë§¤ì¹­ ---\n",
        "def match_shorts_to_segments(shorts_points, segments, threshold=0.5, window_size=5):\n",
        "    windows = build_windows(segments, window_size)\n",
        "    results = []\n",
        "    for short in shorts_points:\n",
        "        best_match = None\n",
        "        best_score = 0\n",
        "        short_text = short.strip()\n",
        "        for window in windows:\n",
        "            score = similarity(short_text, window[\"text\"])\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_match = window\n",
        "        if best_score >= threshold:\n",
        "            results.append((short, best_match[\"start\"], best_match[\"end\"]))\n",
        "        else:\n",
        "            results.append((short, None, None))\n",
        "    return results\n",
        "\n",
        "# --- 6. ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥ ---\n",
        "def write_output(file_path, matched):\n",
        "    with open(file_path, 'w', encoding='utf-8') as file:\n",
        "        for text, start, end in matched:\n",
        "            if start is not None:\n",
        "                file.write(f\"{text} - ì‹œì‘: {start:.2f}, ì¢…ë£Œ: {end:.2f}\\n\")\n",
        "            else:\n",
        "                file.write(f\"{text} - âŒ ë§¤ì¹­ ì‹¤íŒ¨\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnS9Bmc8JU8I"
      },
      "source": [
        "## ì˜ìƒ ìë¥´ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL2pm9Jw16o5"
      },
      "outputs": [],
      "source": [
        "# fps ì¶”ì¶œ\n",
        "import ffmpeg\n",
        "\n",
        "def get_video_fps(file_path):\n",
        "    probe = ffmpeg.probe(file_path, v='error', select_streams='v:0', show_entries='stream=r_frame_rate')\n",
        "    print(probe)\n",
        "    if not probe['streams']:\n",
        "      raise ValueError(\"ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
        "\n",
        "    fps = probe['streams'][0]['r_frame_rate']\n",
        "    numerator, denominator = map(float, fps.split('/'))\n",
        "    return numerator / denominator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5u77A1BJgkY"
      },
      "source": [
        "## ì‡¼ì¸  ë¶€ë¶„ ìë¥´ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t2qs0oVrrQp",
        "outputId": "a1d61b9a-418f-4792-f8c3-af1066688bc6"
      },
      "outputs": [],
      "source": [
        "from moviepy.editor import VideoFileClip\n",
        "import re\n",
        "\n",
        "\n",
        "def load_timestamps_from_file(text_file):\n",
        "    shorts_info = []\n",
        "    # ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ ì—…ë°ì´íŠ¸ (í…ìŠ¤íŠ¸ì™€ íƒ€ì„ìŠ¤íƒ¬í”„ ë¶„ë¦¬)\n",
        "    pattern = r'^(.*?) - ì‹œì‘: (\\d+\\.\\d+), ì¢…ë£Œ: (\\d+\\.\\d+)'\n",
        "\n",
        "    with open(text_file, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            match = re.match(pattern, line)\n",
        "            if match:\n",
        "                text = match.group(1).strip()\n",
        "                start_time = float(match.group(2))\n",
        "                end_time = float(match.group(3))\n",
        "                shorts_info.append((text, start_time, end_time))\n",
        "    return shorts_info\n",
        "\n",
        "\n",
        "def cut_and_save_video(video_path, start_time, end_time, output_path, fps):\n",
        "    # ë™ì˜ìƒ íŒŒì¼ ë¡œë“œ\n",
        "    clip = VideoFileClip(video_path)\n",
        "    # ì£¼ì–´ì§„ ì‹œì‘ê³¼ ì¢…ë£Œ ì‹œê°„ì— ë”°ë¼ í´ë¦½ ìë¥´ê¸°\n",
        "    short_clip = clip.subclip(start_time, end_time)\n",
        "    # ìƒˆë¡œìš´ íŒŒì¼ë¡œ ì €ì¥\n",
        "    short_clip.write_videofile(output_path, codec=\"libx264\", fps=fps)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5yk61PdJrGw"
      },
      "source": [
        "## ë©”ì¸"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiYJMY7iru_3",
        "outputId": "5381a1f4-f6cd-49d2-dc6a-3ae86ddc0518"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "   # 1. ìœ íŠœë¸Œ mp3 ë‹¤ìš´ë¡œë“œ\n",
        "    url = \"https://youtu.be/fre34cEeAYs?si=2JjkPcHBNmXsHurL\"\n",
        "    mp3_path = \"youtube_output\"\n",
        "    mp4_path = \"youtube_output\"\n",
        "    url_to_mp4(url, mp4_path)\n",
        "    url_to_mp3(url, mp3_path)\n",
        "\n",
        "    # ì‹¤ì œ mp3ëŠ” ìœ„ì—ì„œ ì§€ì •í•œ ì´ë¦„ìœ¼ë¡œ ì €ì¥ë¨\n",
        "    mp3_file_path = \"youtube_output.mp3\"\n",
        "\n",
        "    full_text_path=\"full_transcription.txt\"\n",
        "\n",
        "    # 2. Whisperë¡œ í…ìŠ¤íŠ¸ ë³€í™˜\n",
        "    mp3_to_text(mp3_file_path, api_key)\n",
        "\n",
        "    # 3. GPTë¡œ ì‡¼ì¸  í¬ì¸íŠ¸ ì¶”ì¶œ\n",
        "    text_to_shorts_points(full_text_path, api_key)\n",
        "\n",
        "    # 4. ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­\n",
        "    segments_file = 'whisper_response.json'\n",
        "    shorts_file = 'shorts_points.txt'\n",
        "    output_file = 'result_by_segment.txt'\n",
        "\n",
        "    segments = read_segments(segments_file)\n",
        "    shorts_points = read_shorts_points(shorts_file)\n",
        "    matched = match_shorts_to_segments(shorts_points, segments,  threshold=0.6, window_size=5)\n",
        "    write_output(output_file, matched)\n",
        "\n",
        "    print(\"ğŸ§© ì„¸ê·¸ë¨¼íŠ¸ ë§¤ì¹­ ë° ì €ì¥ ì™„ë£Œ\")\n",
        "\n",
        "    # 5. ì˜ìƒì—ì„œ ì‡¼ì¸  ìë¥´ê¸°\n",
        "    video_file = 'youtube_output.mp4'  # âš ï¸ ì§ì ‘ í¸ì§‘í•œ ì˜ìƒ ìœ„ì¹˜ë¡œ ì„¤ì • í•„ìš”\n",
        "    output_folder = 'output_clips\\\\'\n",
        "\n",
        "    shorts_info = load_timestamps_from_file(output_file)\n",
        "\n",
        "    fps = get_video_fps(video_file)\n",
        "\n",
        "    for idx, (text, start_time, end_time) in enumerate(shorts_info):\n",
        "        if start_time is not None and end_time is not None:\n",
        "            output_path = f\"{output_folder}short_clip_{idx + 1}.mp4\"\n",
        "            cut_and_save_video(video_file, start_time, end_time, output_path,fps)\n",
        "            print(f\"ğŸ¬ ì‡¼ì¸  {idx + 1} ì €ì¥ ì™„ë£Œ: {output_path}\")\n",
        "        else:\n",
        "            print(f\"âš ï¸ ì‡¼ì¸  {idx + 1}ëŠ” ë§¤ì¹­ ì‹¤íŒ¨ë¡œ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    print(\"âœ… ì „ì²´ ì‘ì—… ì™„ë£Œ!\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
